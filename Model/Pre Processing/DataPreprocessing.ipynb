{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\fpt47\\Downloads\\car_detail_en.csv\")\n",
    "df.head(5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = df[\"url\"]\n",
    "print(links)\n",
    "links.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.page_load_strategy = 'none'  # Set the page load strategy\n",
    "\n",
    "driver = webdriver.Chrome(options = options)  # Pass the options to the WebDriver\n",
    "with open(\"day_post.txt\", \"a\", encoding='utf-8') as f:\n",
    "    start = 961\n",
    "    for i, link in enumerate(links[start:]):\n",
    "        driver.get(link)\n",
    "        current_link = driver.current_url\n",
    "        if link != current_link:\n",
    "            print(i + 1 + start)\n",
    "            print(f\"Redirect occurred!\")\n",
    "            f.write(\"Redirect occurred!\" + \"\\n\")\n",
    "        else:\n",
    "            wait = WebDriverWait(driver, 3)\n",
    "            class_notes = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"notes\")))\n",
    "            print(i + 1 + start)\n",
    "            print(class_notes.text)\n",
    "            f.write(class_notes.text + \"\\n\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_dir = \"C:/Users/fpt47/AppData/Local/Google/Chrome/User Data - Copy\"\n",
    "service = Service(executable_path = \"D:/fpt47/Downloads/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "options = Options()\n",
    "options.page_load_strategy = 'none'\n",
    "options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "options.add_argument(\"--profile-directory=Default\")\n",
    "\n",
    "driver = webdriver.Chrome(service = service, options=options)\n",
    "driver.get(links[0])\n",
    "\n",
    "try:\n",
    "    # Find the iframe\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    iframe = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"iframe\")))\n",
    "\n",
    "    # Switch to the iframe's context\n",
    "    driver.switch_to.frame(iframe)\n",
    "\n",
    "    # Now you can find the element within the iframe\n",
    "    recaptcha_button = wait.until(EC.presence_of_element_located((By.ID, \"recaptcha-anchor\")))\n",
    "\n",
    "    # Interact with the element (e.g., click it)\n",
    "    time.sleep(random.uniform(4, 5))\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(recaptcha_button).perform()\n",
    "    recaptcha_button.click()\n",
    "except TimeoutException:\n",
    "    # If iframe is not found, handle the exception\n",
    "    print(\"The iframe is not present on the page. Performing alternative action...\")\n",
    "finally:\n",
    "    # Switch back to the main content after interacting with the element\n",
    "    driver.switch_to.default_content()\n",
    "\n",
    "    # # Set the page load strategy\n",
    "    # user_data_dir = r\"C:\\Users\\fpt47\\AppData\\Local\\Google\\Chrome\\User Data - Copy - Copy\"\n",
    "    # service = Service(executable_path = \"D:/fpt47/Downloads/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "    # options = Options()\n",
    "    # options.page_load_strategy = 'none'\n",
    "    # options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "    # options.add_argument(\"--profile-directory=Default\")\n",
    "\n",
    "    # driver = webdriver.Chrome(service = service, options=options)\n",
    "    # driver.get(links[0])\n",
    "\n",
    "    with open(\"day_post.txt\", \"a\", encoding = 'utf-8') as f:\n",
    "        start = 1229\n",
    "        for i, link in enumerate(links[start:]):\n",
    "            driver.get(link)\n",
    "            current_link = driver.current_url\n",
    "            if link != current_link:\n",
    "                print(i + 1 + start)\n",
    "                print(f\"Redirect occurred!\")\n",
    "                f.write(\"Redirect occurred!\" + \"\\n\")\n",
    "            else:\n",
    "                wait = WebDriverWait(driver, 3)\n",
    "                class_notes = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"notes\")))\n",
    "                print(i + 1 + start)\n",
    "                print(class_notes.text)\n",
    "                f.write(class_notes.text + \"\\n\")\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_post = []\n",
    "with open(\"day_post.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = line.split()\n",
    "        if line[0] == \"Redirect\":\n",
    "            print(\"NULL\")\n",
    "            day_post.append(None)\n",
    "        else:\n",
    "            day = line[2]      \n",
    "            print(day)\n",
    "            day_post.append(day)\n",
    "        line = f.readline()\n",
    "df[\"posting_date\"] = day_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xử lý giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_to_number(text):\n",
    "    \"\"\"\n",
    "    Converts text like \"3 Billion 550 Million\" to a numeric value.\n",
    "    Handles cases with missing billions or millions.\n",
    "    \"\"\"\n",
    "    word_to_num = {\n",
    "        \"Billion\": 1,\n",
    "        \"Million\": 1e-3\n",
    "    }\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    pattern = r\"(\\d+)?( Billion| Million)?\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    total = 0\n",
    "    for match in matches:\n",
    "        num, word = match\n",
    "        if not word:\n",
    "            pass\n",
    "        else:\n",
    "            total += float(num)*word_to_num[word.strip()]\n",
    "    return round(total, 3)\n",
    "df = df.rename(columns = {\"price. price\": \"price\"})\n",
    "df[\"price_in_billion\"] = df[\"price\"].apply(text_to_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing describe row scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\fpt47\\Downloads\\miss_describe.txt\"\n",
    "miss_describe_row_index = []\n",
    "with open(file_path, \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        row_index = int(line.strip())\n",
    "        miss_describe_row_index.append(row_index)\n",
    "        # print(row_index)\n",
    "        line = f.readline()\n",
    "# print(miss_describe_row_index)\n",
    "print(len(miss_describe_row_index))\n",
    "for i in miss_describe_row_index:\n",
    "    print(df.at[i, \"describe\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.page_load_strategy = 'none'  # Set the page load strategy\n",
    "\n",
    "driver = webdriver.Chrome(options = options)  # Pass the options to the WebDriver\n",
    "with open(\"missing_describe.txt\", \"a\", encoding='utf-8') as f:\n",
    "    for i in miss_describe_row_index:\n",
    "        link = links[i]\n",
    "        print(link)\n",
    "        driver.get(link)\n",
    "        current_link = driver.current_url\n",
    "        if link != current_link:\n",
    "            print(i)\n",
    "            print(f\"Redirect occurred!\")\n",
    "            f.write(str(i) + \"\\n\")\n",
    "            f.write(\"Redirect occurred!\" + \"\\n\")\n",
    "        else:\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            class_notes = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"des_txt\")))\n",
    "            print(i)\n",
    "            print(class_notes.text)\n",
    "            f.write(str(i) + \"\\n\")\n",
    "            f.write(class_notes.text + \"\\n\")\n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Năm sản xuất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.page_load_strategy = 'none'  # Set the page load strategy\n",
    "\n",
    "miss_year_produce_row_index = [880, 977, 1784, 1806, 1948, 2540, 3543, 4054, \n",
    "    4180, 5585, 9913, 10518, 10703, 11321, 11561, \n",
    "    11573, 12886, 14640, 14703, 14916, 15334, 16888, \n",
    "    17358, 17839, 19102, 21962, 22456, 23327, 24057, 28767, 29309, 30526]\n",
    "driver = webdriver.Chrome(options = options)  # Pass the options to the WebDriver\n",
    "with open(\"year_produce.txt\", \"a\", encoding='utf-8') as f:\n",
    "    for i in miss_year_produce_row_index:\n",
    "        link = links[i]\n",
    "        print(link)\n",
    "        driver.get(link)\n",
    "        current_link = driver.current_url\n",
    "        if link != current_link:\n",
    "            print(i)\n",
    "            print(f\"Redirect occurred!\")\n",
    "            f.write(str(i) + \"\\n\")\n",
    "            f.write(\"Redirect occurred!\" + \"\\n\")\n",
    "        else:\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            class_notes = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"inp\")))\n",
    "            print(i)\n",
    "            print(class_notes.text)\n",
    "            f.write(str(i) + \"\\n\")\n",
    "            f.write(class_notes.text + \"\\n\")\n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive type (Dẫn động)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df[\"drive_type\"] == \"-\")\n",
    "df_none_drive_type = df[filt]\n",
    "df_none_drive_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_drive_type_links = df_none_drive_type[\"url\"]\n",
    "\n",
    "user_data_dir = \"C:/Users/fpt47/AppData/Local/Google/Chrome/User Data - Copy\"\n",
    "service = Service(executable_path = \"D:/fpt47/Downloads/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "options = Options()\n",
    "options.page_load_strategy = 'none'\n",
    "options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "options.add_argument(\"--profile-directory=Default\")\n",
    "\n",
    "driver = webdriver.Chrome(service = service, options=options)\n",
    "first_link_drive_type = r\"https://bonbanh.com/xe-mercedes_benz-e_class-mercedes_e200-ex-2022-4879606\"\n",
    "driver.get(first_link_drive_type)\n",
    "\n",
    "try:\n",
    "    # Find the iframe\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    iframe = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"iframe\")))\n",
    "\n",
    "    # Switch to the iframe's context\n",
    "    driver.switch_to.frame(iframe)\n",
    "\n",
    "    # Now you can find the element within the iframe\n",
    "    recaptcha_button = wait.until(EC.presence_of_element_located((By.ID, \"recaptcha-anchor\")))\n",
    "\n",
    "    # Interact with the element (e.g., click it)\n",
    "    time.sleep(random.uniform(9, 10))\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(recaptcha_button).perform()\n",
    "    recaptcha_button.click()\n",
    "except TimeoutException:\n",
    "    # If iframe is not found, handle the exception\n",
    "    print(\"The iframe is not present on the page. Performing alternative action...\")\n",
    "finally:\n",
    "    # Switch back to the main content after interacting with the element\n",
    "    driver.switch_to.default_content()\n",
    "\n",
    "    miss_drive_type_links = df_none_drive_type[\"url\"]\n",
    "\n",
    "    with open(\"drive_type.txt\", \"a\", encoding='utf-8') as f:\n",
    "        start = 0\n",
    "        for i, link in enumerate(miss_drive_type_links):\n",
    "            driver.get(link)\n",
    "            current_link = driver.current_url\n",
    "            if link != current_link:\n",
    "                print(i + 1 + start)\n",
    "                print(f\"Redirect occurred!\")\n",
    "                f.write(\"Redirect occurred!\" + \"\\n\")\n",
    "            else:\n",
    "                wait = WebDriverWait(driver, 3)\n",
    "                class_notes = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[3]/div[5]/div[1]/div[2]/div[6]/div[2]/span\")))\n",
    "                print(i + 1 + start)\n",
    "                print(class_notes.text)\n",
    "                f.write(class_notes.text + \"\\n\")\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_drive_type = []\n",
    "with open(\"drive_type.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        if len(line) > 3 and ('-' in line):\n",
    "            found_drive_type.append(line[0:3])\n",
    "        else:\n",
    "            found_drive_type.append(\"-\")\n",
    "        line = f.readline()\n",
    "df_none_drive_type[\"drive_type\"] = found_drive_type\n",
    "df.update(df_none_drive_type[\"drive_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine (Động cơ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engine = pd.read_csv(r\"D:\\fpt47\\Downloads\\engine_car_detail_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4418     NaN\n",
       "28992    NaN\n",
       "29279    NaN\n",
       "29375    NaN\n",
       "29467    NaN\n",
       "Name: engine_capacity, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = (df_engine[\"engine\"] == \"-\")\n",
    "df_none_engine = df_engine[filt]\n",
    "df_none_engine[\"engine_capacity\"].head()\n",
    "# df_none_engine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Xăng 2.0 L\n",
      "2\n",
      "Xăng 2.4 L\n",
      "3\n",
      "Dầu 2.0 L\n",
      "4\n",
      "Xăng 1.6 L\n",
      "5\n",
      "Xăng 1.6 L\n",
      "6\n",
      "Xăng 1.6 L\n",
      "7\n",
      "Xăng 1.2 L\n",
      "8\n",
      "Xăng 1.5 L\n",
      "9\n",
      "Dầu 2.5 L\n",
      "10\n",
      "Xăng 3.0 L\n",
      "11\n",
      "Xăng 2.4 L\n",
      "12\n",
      "Dầu 2.5 L\n",
      "13\n",
      "Xăng 1.25 L\n",
      "14\n",
      "Xăng 1.4 L\n",
      "15\n",
      "Xăng 1.4 L\n",
      "16\n",
      "Xăng 1.5 L\n",
      "17\n",
      "Xăng 1.6 L\n",
      "18\n",
      "Xăng 1.2 L\n",
      "19\n",
      "Xăng 2.0 L\n",
      "20\n",
      "Xăng 1.0 L\n",
      "21\n",
      "Xăng 2.5 L\n",
      "22\n",
      "Xăng 2.0 L\n",
      "23\n",
      "Xăng 2.4 L\n",
      "24\n",
      "Xăng 2.0 L\n"
     ]
    }
   ],
   "source": [
    "miss_engine_links = df_none_engine[\"url\"]\n",
    "\n",
    "user_data_dir = \"C:/Users/fpt47/AppData/Local/Google/Chrome/User Data - Copy\"\n",
    "service = Service(executable_path = \"D:/fpt47/Downloads/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "options = Options()\n",
    "options.page_load_strategy = 'none'\n",
    "options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "options.add_argument(\"--profile-directory=Default\")\n",
    "\n",
    "driver = webdriver.Chrome(service = service, options=options)\n",
    "first_link_engine = r\"https://bonbanh.com/xe-volvo-xc60-recharge-2023-4686031\"\n",
    "driver.get(first_link_engine)\n",
    "\n",
    "try:\n",
    "    # Find the iframe\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    iframe = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"iframe\")))\n",
    "\n",
    "    # Switch to the iframe's context\n",
    "    driver.switch_to.frame(iframe)\n",
    "\n",
    "    # Now you can find the element within the iframe\n",
    "    recaptcha_button = wait.until(EC.presence_of_element_located((By.ID, \"recaptcha-anchor\")))\n",
    "\n",
    "    # Interact with the element (e.g., click it)\n",
    "    time.sleep(random.uniform(4, 5))\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(recaptcha_button).perform()\n",
    "    recaptcha_button.click()\n",
    "except TimeoutException:\n",
    "    # If iframe is not found, handle the exception\n",
    "    print(\"The iframe is not present on the page. Performing alternative action...\")\n",
    "finally:\n",
    "    # Switch back to the main content after interacting with the element\n",
    "    driver.switch_to.default_content()\n",
    "\n",
    "    miss_engine_links = df_none_engine[\"url\"]\n",
    "\n",
    "    with open(\"engine.txt\", \"a\", encoding='utf-8') as f:\n",
    "        start = 0\n",
    "        for i, link in enumerate(miss_engine_links):\n",
    "            driver.get(link)\n",
    "            current_link = driver.current_url\n",
    "            if link != current_link:\n",
    "                print(i + 1 + start)\n",
    "                print(f\"Redirect occurred!\")\n",
    "                f.write(\"Redirect occurred!\" + \"\\n\")\n",
    "            else:\n",
    "                wait = WebDriverWait(driver, 15)\n",
    "                class_notes = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[3]/div[5]/div[1]/div[2]/div[1]/div[2]/span\")))\n",
    "                print(i + 1 + start)\n",
    "                print(class_notes.text)\n",
    "                f.write(class_notes.text + \"\\n\")\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_engine = []\n",
    "found_engine_capacity = []\n",
    "with open(\"engine.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = line.split()\n",
    "        found_engine.append(line[0])\n",
    "        found_engine_capacity.append(line[1] + \" \" + line[2])\n",
    "        line = f.readline()\n",
    "df_none_engine[\"engine\"] = found_engine\n",
    "df_none_engine[\"engine_capacity\"] = found_engine_capacity\n",
    "df_engine.update(df_none_engine[[\"engine\", \"engine_capacity\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Handle missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2 = pd.read_csv(r\"D:\\fpt47\\Downloads\\car_detail_en (version 2).csv\")\n",
    "df_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.replace(\"-\", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_group_mode(group):\n",
    "    mode_series = group['interior_color'].mode()\n",
    "    if not mode_series.empty:\n",
    "        group['interior_color'] = group['interior_color'].fillna(mode_series.iloc[0])\n",
    "    else:\n",
    "        # Handle the case where mode_series is empty (no mode found)\n",
    "        # For example, fill missing values with a default value\n",
    "        group['interior_color'] = group['interior_color'].fillna('Default Value')\n",
    "    return group\n",
    "\n",
    "df_v2 = df_v2.groupby([\"exterior_color\", \"grade\", \"year_of_manufacture\"]).apply(fill_group_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Dao_version_1.csv\")\n",
    "df1.set_index(\"ad_id\", inplace = True)\n",
    "# df_v2.set_index(\"ad_id\", inplace = True)\n",
    "df1.update(df_v2[\"interior_color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"interior_color.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Dao_version_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad_id</th>\n",
       "      <th>exterior_color</th>\n",
       "      <th>interior_color</th>\n",
       "      <th>grade</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2676458</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CX5</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>3157424</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3164470</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CX5</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>3164574</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CX5</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>3251335</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ad_id exterior_color interior_color grade  year_of_manufacture\n",
       "147  2676458            Red            NaN   CX5               2023.0\n",
       "185  3157424          Green            NaN     2               2023.0\n",
       "187  3164470          Green            NaN   CX5               2023.0\n",
       "188  3164574          White            NaN   CX5               2023.0\n",
       "207  3251335          Green            NaN     2               2023.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interior_handling = df_v2[[\"ad_id\", \"exterior_color\", \"interior_color\", \"grade\", \"year_of_manufacture\"]]\n",
    "filt = (df_interior_handling[\"interior_color\"].isna())\n",
    "df_missing_interior = df_interior_handling.loc[filt]\n",
    "df_missing_interior.head()\n",
    "# print(df_missing_interior.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined key column in both DataFrames\n",
    "df_missing_interior.loc[:, 'key'] = df_missing_interior['exterior_color'] + '_' + df_missing_interior['grade'] + '_' + df_missing_interior['year_of_manufacture'].apply(str)\n",
    "df_interior_handling.loc[:, 'key'] = df_interior_handling['exterior_color'] + '_' + df_interior_handling['grade'] + '_' + df_interior_handling['year_of_manufacture'].apply(str)\n",
    "df_interior_handling.rename(columns = {\"interior_color\": \"handling_interior_color\"}, inplace = True)\n",
    "df_missing_interior.rename(columns = {\"interior_color\": \"missing_interior_color\"}, inplace = True)\n",
    "# df_interior_handling.head()\n",
    "# df_missing_interior.head()\n",
    "# Merge the DataFrames on the key column\n",
    "merged_df = pd.merge(df_missing_interior, df_interior_handling[['key', \"handling_interior_color\"]], on='key', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[:, \"interior_color\"] = merged_df[\"handling_interior_color\"]\n",
    "merged_df.drop([\"handling_interior_color\", \"missing_interior_color\"], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (merged_df[\"interior_color\"] == \"-\")\n",
    "merged_df =  merged_df.loc[~filt]\n",
    "merged_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Found Mileage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_found_mileage = pd.read_csv(r\"C:\\Users\\fpt47\\OneDrive\\Documents\\found_mileage.csv\")\n",
    "import re\n",
    "def text_to_number(text):\n",
    "    \"\"\"\n",
    "    Converts text like \"3 Billion 550 Million\" to a numeric value.\n",
    "    Handles cases with missing billions or millions.\n",
    "    \"\"\"\n",
    "    word_to_num = {\n",
    "        \"Billion\": 1,\n",
    "        \"Million\": 1e-3\n",
    "    }\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    pattern = r\"(\\d+)?( Billion| Million)?\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    total = 0\n",
    "    for match in matches:\n",
    "        num, word = match\n",
    "        if not word:\n",
    "            pass\n",
    "        else:\n",
    "            total += float(num)*word_to_num[word.strip()]\n",
    "    return round(total, 3)\n",
    "df_found_mileage[\"Price\"] = df_found_mileage[\"Price\"].apply(text_to_number)\n",
    "df_found_mileage[\"Mileage\"] = df_found_mileage[\"Mileage\"].apply(lambda x: int((str(x).split())[0].replace(\".\", \"\")))\n",
    "df_found_mileage.to_csv(\"active_found_mileage.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_found_mileage[\"Compare_Mileage\"] = df_found_mileage[\"Compare_Price\"]*df_found_mileage[\"Mileage\"]/df_found_mileage[\"Price\"]\n",
    "grouped_means = df_found_mileage.groupby(\"ID\")[\"Compare_Mileage\"].mean()\n",
    "df_found_mileage = pd.DataFrame({\"ID\": grouped_means.index, \"Mean_Mileage\": grouped_means.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_found_mileage[\"Mean_Mileage\"] = df_found_mileage[\"Mean_Mileage\"].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_found_mileage.to_csv(\"active_found_mileage.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tâm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_mileage_Tam = pd.read_csv(r\"D:\\fpt47\\Downloads\\new_mileage_Tam.csv\")\n",
    "df_new_mileage_Tam.set_index(\"ad_id\", inplace = True)\n",
    "df = pd.read_csv(\"Dao_version_2.csv\")\n",
    "df.set_index(\"ad_id\", inplace = True)\n",
    "df[\"Tam_mileage\"] = df_new_mileage_Tam[\"num_mileage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Tam_mileage\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df[\"Tam_mileage\"] > 0) & (df[\"mileage\"] < 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dao_version_Vanh_mileage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = df[\"url\"]\n",
    "print(links)\n",
    "links.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_dir = \"C:/Users/fpt47/AppData/Local/Google/Chrome/User Data - Copy\"\n",
    "service = Service(executable_path = \"D:/fpt47/Downloads/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "options = Options()\n",
    "options.page_load_strategy = 'none'\n",
    "options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "options.add_argument(\"--profile-directory=Default\")\n",
    "\n",
    "driver = webdriver.Chrome(service = service, options=options)\n",
    "driver.get(links[0])\n",
    "\n",
    "try:\n",
    "    # Find the iframe\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    iframe = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"iframe\")))\n",
    "\n",
    "    # Switch to the iframe's context\n",
    "    driver.switch_to.frame(iframe)\n",
    "\n",
    "    # Now you can find the element within the iframe\n",
    "    recaptcha_button = wait.until(EC.presence_of_element_located((By.ID, \"recaptcha-anchor\")))\n",
    "\n",
    "    # Interact with the element (e.g., click it)\n",
    "    time.sleep(random.uniform(4, 5))\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(recaptcha_button).perform()\n",
    "    recaptcha_button.click()\n",
    "except TimeoutException:\n",
    "    # If iframe is not found, handle the exception\n",
    "    print(\"The iframe is not present on the page. Performing alternative action...\")\n",
    "finally:\n",
    "    # Switch back to the main content after interacting with the element\n",
    "    driver.switch_to.default_content()\n",
    "\n",
    "    with open(\"price.txt\", \"a\", encoding = 'utf-8') as f:\n",
    "        start = 921\n",
    "        for i, link in enumerate(links[start:]):\n",
    "            driver.get(link)\n",
    "            current_link = driver.current_url\n",
    "            if link != current_link:\n",
    "                print(i + 1 + start)\n",
    "                print(f\"Redirect occurred!\")\n",
    "                f.write(\"Redirect occurred!\" + \"\\n\")\n",
    "            else:\n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                try:\n",
    "                    class_notes = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[3]/div[3]/h1\")))\n",
    "                    print(i + 1 + start)\n",
    "                    print(class_notes.text)\n",
    "                    f.write(class_notes.text + \"\\n\")\n",
    "\n",
    "                except TimeoutException:\n",
    "                    print(i + 1 + start)\n",
    "                    print(\"Timed out waiting for class notes element.\")\n",
    "                    f.write(\"Timed out waiting for class notes element.\" + \"\\n\")\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_price_index = []\n",
    "with open(\"price.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "with open(\"price_v2.txt\", \"a\", encoding = 'utf-8') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if (\"Million\" in line) or (\"Billion\" in line):\n",
    "            exist_price_index.append(i)\n",
    "            price = line.split(\"-\")[-1].strip()\n",
    "            f.write(price + \"\\n\")\n",
    "        else:\n",
    "            f.write(\"0\" + \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30568\n"
     ]
    }
   ],
   "source": [
    "print(len(exist_price_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dao_version_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"price_v2.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "for i in exist_price_index:\n",
    "    df.loc[i, \"price\"] = lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_in_billion\"] = df[\"price\"].apply(text_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dao_version_price_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(df_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dao_version_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_and_seat = pd.read_csv(r\"D:\\fpt47\\Downloads\\door_and_seat.csv\")\n",
    "car_detail_grade_processing = pd.read_csv(r\"D:\\fpt47\\Downloads\\car_detail_grade_processing.csv\")\n",
    "door_and_seat.set_index(\"ad_id\", inplace = True)\n",
    "car_detail_grade_processing.set_index(\"ad_id\", inplace = True)\n",
    "df.set_index(\"ad_id\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(door_and_seat)\n",
    "df.update(car_detail_grade_processing[[\"brand\", \"grade\", \"car_name\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"engine_capacity\"] = df_engine[\"engine_capacity\"]\n",
    "df.update(df_engine[\"engine\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Số cột còn thiếu data: engine_capacity, fuel_consumption (An), condittion, car_model (Tâm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_capacity_fuel_consumption = pd.read_csv(r\"D:\\fpt47\\Downloads\\An_engine_cap_fuel_consumption.csv\")\n",
    "engine_capacity_fuel_consumption.set_index(\"ad_id\", inplace = True)\n",
    "df.set_index(\"ad_id\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(engine_capacity_fuel_consumption[[\"engine_capacity\", \"fuel_consumption\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mileage_Tam = pd.read_csv(r\"D:\\fpt47\\Downloads\\new_mileage_Tam.csv\")\n",
    "new_mileage_Tam.set_index(\"ad_id\", inplace = True)\n",
    "df.set_index(\"ad_id\", inplace = True)\n",
    "df.update(new_mileage_Tam[[\"mileage\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dao_version_1.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format mileage, engine_capacity\n",
    "df[\"mileage\"] = df[\"mileage\"].apply(lambda x: int((str(x).split())[0].replace(\",\", \"\")))\n",
    "df[\"engine_capacity\"] = df[\"engine_capacity\"].apply(lambda x: float((str(x).split())[0]))\n",
    "df.to_csv(\"Dao_version_2.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dao_version_2.csv\")\n",
    "df_potential_error_mileage = df[(df[\"mileage\"] < 100) & (df[\"mileage\"] > 0)]\n",
    "df_potential_error_mileage.to_csv(\"potential_error_mileage.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update mileage của Vanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active_found_mileage = pd.read_csv(\"active_found_mileage.csv\")\n",
    "df_active_found_mileage.set_index(\"ID\", inplace = True)\n",
    "df = pd.read_csv(\"Dao_version_2.csv\")\n",
    "df.set_index(\"ad_id\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active_found_mileage[\"Mean_Mileage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df_active_found_mileage.index, \"mileage\"] = df_active_found_mileage[\"Mean_Mileage\"]\n",
    "df.to_csv(\"Dao_version_Vanh_mileage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dao_version_price_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"grade\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
